---
layout: post
title:  "Blog 4: RNN Baseline"
---

For this blog post, we completed the first baseline approach. We followed a very similar baseline as the one given in the paper: we present an RNN-only baseline. For this baseline, we use AllenNLP to run our experiments on the given data.

# 
To summarize, we report 50.7% accuracy on the train data, and 50.9% accuracy on the dev data. This is very close to the text-only baseline presented in Suhr et al. 2018 (https://arxiv.org/pdf/1811.00491.pdf). Our presented evaluation framework is the dev accuracy, which is given as 50.9%.

Our model uses 100d GloVe embeddings, and encodes the text via a 100d BiLSTM. This is then fed into a two layer feedforward classifier. Our input is batched in 32-pair segments.

It's important to note here that this is an important baseline - many previous VQA sets could be solved via a text-only basis. However, it's important also to note why the text-only baseline does not succeed here. The same sentence is used more than once - for example, it might be used 4 times, and in two occurrences the answer might be true, and false twice.
