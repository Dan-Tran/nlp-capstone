---
layout: post
title:  "Blog 4: Text-Only RNN Baseline"
---

For this blog post, we completed the first baseline approach for our task that will be used in our evaluation of how successful our project will be.  For this baseline, we used a very similar baseline to the one given in the original research paper for the NLVR2 dataset. This is simply using an RNN and feeding in the caption to output true or false, thus ignoring the image pairs.

We used AllenNLP to implement the model and run our experiments on the given data. For each training instance, the given caption is embeded using the 100 dimensional GloVe pretrained embeddings formed from Wikipedia on 2014 and on Gigaword 5. This text embedding is then fed into a 100 dimensional bidirectional LSTM. This is then fed into a two layer feedforward classifier. Our input was batched in 32-pair segments.

With this model, we were able to achieve a 50.7% accuracy on the training data and a 50.9% accuracy on the development data. This is very similar to the text-only baseline presented in [Suhr et al. 2018](https://arxiv.org/pdf/1811.00491.pdf). Our presented evaluation framework is the dev accuracy, which is given as 50.9%.

It's important to note here that this is an important baseline. Many previous VQA sets could be solved decently well by just looking at the text portion of the training instance and ignoring the visual portion. As we can see, for this dataset with just text only we were unable to substantially perform better than random chance or simply labeling everything using the majority class. It's important also to note why the text-only baseline does not succeed here. The dataset is designed in a way that makes it difficult to solve this task by only looking at the text and tries to eliminate any potential bias. For example, the same caption is used for more than just one image pair. It might be used 4 times, and in two occurrences the answer might be true and in the other two occurences the answer might be false, thus reducing the association between some sentences towards a particular answer.

The code for this baseline is located at [https://github.com/Dan-Tran/nlp-capstone/tree/master/blogcode/blog4](https://github.com/Dan-Tran/nlp-capstone/tree/master/blogcode/blog4).