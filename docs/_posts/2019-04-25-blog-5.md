---
layout: post
title:  "Blog 5: RNN + CNN Baseline"
---

Here, we completed the second baseline mentioned in [Suhr et al. 2018](https://arxiv.org/pdf/1811.00491.pdf). This baseline concats the RNN along with each of the images passed through CNN. This results in a ~16,000d vector that is then passed through an MLP and makes a prediction. This uses the text and image together, and is aptly described the "text + image" baseline in the NLVR2 paper.

We used AllenNLP to implement the model and run our experiments on the given data. We ran each model through two Conv2D layers, then a MaxPool layer. It continued to run the results of the MaxPool layer through two Conv2D layers, then through two average pooling layers. It then takes the final result of the CNN and flattens it to produce a vector. Finally, it takes that vector, the output of the RNN presented in the last section, and feeds it through a feedforward layer to finalize a prediction.

With this model, we were able to achieve a 98.7% accuracy on the training data and a 51.4% accuracy on the development data. This is very similar to the text-only baseline presented in [Suhr et al. 2018](https://arxiv.org/pdf/1811.00491.pdf). Our presented evaluation framework is the dev accuracy, which is given as 51.4%.

The code for this baseline is located at [https://github.com/Dan-Tran/nlp-capstone/tree/master/blogcode/blog4](https://github.com/Dan-Tran/nlp-capstone/tree/master/blogcode/blog5).
