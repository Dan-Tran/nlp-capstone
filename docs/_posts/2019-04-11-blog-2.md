---
layout: post
title:  "Blog 2: Pros and Cons"
---

## Pros and Cons for each Project

### NLVR2 - Visual QA with Real Images.

#### Pros

* Since it is a newer dataset, it is easier to improve upon existing models without excessive use of resources (GPU arms race) 
* The answer space is binary (True/False) so evaluation more straight forward.
* Relatively easy to improve on existing models for the task.

#### Cons

* Computer vision (CV) tasks are likely outside the expertise of the course staff, so we will need to rely on our own schema much more heavily.
* Existing models/baselines barely do better than random guessing (Random ~50, Baselines ~50-54), so we’ll most likely have to design a new model.
* Dataset is quite large, so simply loading the data is resource intensive

### VCR - Visual Commonsense Reasoning.

#### Pros

* The R2C model that performs decently on this task is open source for us to research and modify. 
    * R2C model was made by UW so we can easily access the researchers
* Tasks consist of three separate subtasks, allowing us to find success in one particular subtask despite potentially not doing well on the others.
* Answering subtask, being multiple choice, has well defined evaluation and discrete answer space.

#### Cons

* Evaluating the generated rationale is difficult 
    * Rationale is generated as an output from the model
* Near impossible for us to beat state of the art and most existing models are not open to public
    * FAIR holds the best model (GPU Arms Race)
    * CKRE from Peking University holds most of the leaderboard, but their code is not available to public/hard to  locate

### ReCoRD - Commonsense reading comprehension.

#### Pros

* Text-only based, so train time will likely be faster than the other two options.
* Text-based common sense has been explored vastly over the last year (OpenAI GPT, ELMo/BERT). Lots of papers and research to work off of.
* Dataset is split into 5 areas so we can focus on a single one (i.e. just “paraphrasing” questions).

#### Cons

* The dataset and task are much more difficult to comprehend compared to the other two tasks.
* The dataset itself is not clean, so it could be training a model on bad data. The human error is relatively high (8%)
* Most state of the art requires the use of ELMo so it is a inherently a resource-intensive task

## Likely Codebases and Platforms

For our project, we will use Python as the programming language and Git as our version control. We will also most likely use the PyTorch machine learning framework to implement our models. We could explore using AllenNLP to implement part of our project, depending on how things go. We will also most likely do some sort of pretraining on our modules, or use pretrained modules like ELMo/BERT and ResNet pretraining.

## Topic for Class

Topics for the class that the team is interested in is Question and Answer systems in natural language process. This could include things like modern formulations of the problem, historic and current methods to do the tasks and the intuition of why the model is designed that way, and ways of evaluating.